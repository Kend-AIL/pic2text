model:
  class_path: dpm.models.p2t.Pic2TextModel
  init_args:
    learning_rate: 4.5e-6
    loss: 
      target: torch.nn.CrossEntropyLoss
      params: 
        ignore_index: 0
    ecconfig:
      target: dpm.modules.encoder.Swinv2encoder
      params:
        image_size: [512,384]
        patch_size: 32
        num_channels: 3
        embed_dim: 128
        depths: [2,2,6,12]
        num_heads: [4,8,8,16]
        window_size: 4
        mlp_ratio: 4.0
        qkv_bias: true
        hidden_dropout_prob: 0.1
        attention_probs_dropout_prob: 0.0
        drop_path_rate: 0.1
        hidden_act: "gelu"
        use_absolute_embeddings: false
        initializer_range: 0.02
        layer_norm_eps: 1e-5
        encoder_stride: 32
        type: "patch"
    dcconfig:
      target: dpm.modules.decoder.Decoder_only
      params:
        d_model: 1024
        num_head: 8
        num_layer: 8
        layer_dim_forward: 3072
        layer_dropout: 0.3
        layer_activation: "gelu"
    ckpt_path: null
    embed_dim: 1024
    gen_strategy: "beam"
    train_strategy: 'sample' #sample--schema sampling #forcing teacher forcing

data:
  class_path: main.DataModuleFromConfig
  init_args:
    batch_size: 4
    train: 
      target: dpm.data.word2vec.ImageTextDataset
      params: 
        json_file_path: './data/deepfashion-multimodal/train_captions.json'
        image_folder_path: './data/deepfashion-multimodal/images'
        image_size: [512,384]
    validation:
      target: dpm.data.word2vec.ImageTextDataset
      params: 
        json_file_path: './data/test_captions.json'
        image_folder_path: './data/deepfashion-multimodal/images'
        image_size: [512,384]
    collect_fn: 
      target: dpm.data.word2vec.datapreprocess
    wrap: false
    num_workers: 16
    pin_memory: False
    prefetch_factor: 2
trainer:
    check_val_every_n_epoch: 4
    max_epochs: 37
    benchmark: True
seed_everything: 43
ckpt_path: null
      