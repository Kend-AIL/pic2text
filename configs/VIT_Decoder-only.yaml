model:
  class_path: dpm.models.p2t.Pic2TextModel
  init_args:
    learning_rate: 0.0005
    loss: 
      target: torch.nn.CrossEntropyLoss
      init:
    ecconfig:
      target: dpm.modules.encoder.ViTencoder
      params:
        hidden_size: 768
        num_hidden_layers: 12
        num_attention_heads: 12
        intermediate_size: 3072
        image_size: [1024,768]
        patch_size: 32
        num_channels: 3
        type: 'all'
    dcconfig:
      target: dpm.modules.decoder.Decoder_only
      params:
        d_model: 768
        num_head: 16
        num_layer: 8
    ckpt_path: null
    embed_dim: 768
    gen_strategy: "greedy"

data:
  class_path: main.DataModuleFromConfig
  init_args:
    batch_size: 8
    train: 
      target: dpm.data.word2vec.ImageTextDataset
      params: 
        json_file_path: './data/deepfashion-multimodal/train_captions.json'
        image_folder_path: './data/deepfashion-multimodal/images'
        image_size: [1024,768]
    validation:
      target: dpm.data.word2vec.ImageTextDataset
      params: 
        json_file_path: './data/test_captions.json'
        image_folder_path: './data/deepfashion-multimodal/images'
        image_size: [1024,768]
    collect_fn: 
      target: dpm.data.word2vec.datapreprocess
    wrap: false
    num_workers: 16
    pin_memory: true
    prefetch_factor: 4
trainer:
    check_val_every_n_epoch: 3
    max_epochs: 30
    benchmark: True
seed_everything: 42
ckpt_path: null
      